# LLM Requirements - For self-hosted LLM inference
# Install this if you want to run LLMs locally on GPU workers

# Hosted LLM APIs (already in main requirements.txt)
openai==1.12.0
anthropic==0.18.0

# Self-hosted LLM inference
vllm==0.2.7
huggingface-hub==0.20.3

# Additional LLM utilities
tiktoken==0.5.2


